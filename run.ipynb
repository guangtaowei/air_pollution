{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.regression import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "# import GridSearchCV\n",
    "\n",
    "import xlrd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "path_DBN = os.path.join(os.path.join(os.path.dirname(os.path.abspath(__file__)), \"models\"), \"deep-belief-network\")\n",
    "sys.path.append(path_DBN)\n",
    "from dbn.tensorflow import SupervisedDBNRegression\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "def dada_handle(items, _use_all_data=True, _use_CCA_data=False, _use_pm25_history=True,\n",
    "                _use_drop_least_importance=False, _start=0, _end=1):\n",
    "    assert not (_use_all_data and _use_CCA_data)\n",
    "    assert _use_all_data or _use_CCA_data or _use_drop_least_importance or _use_pm25_history\n",
    "    assert (not _use_drop_least_importance) or (\n",
    "            (not _use_all_data) and (not _use_CCA_data) and _use_drop_least_importance)\n",
    "\n",
    "    if not use_pm25_history:\n",
    "        items.pop('pm25')\n",
    "    if use_drop_least_importance:\n",
    "        items.pop('weather')\n",
    "        items.pop('wind')\n",
    "    elif use_CCA_data:  # pm10,co,temperature,moisture\n",
    "        items.pop('hour')\n",
    "        items.pop('o3')\n",
    "        items.pop('so2')\n",
    "        items.pop('no2')\n",
    "        items.pop('wind')\n",
    "        items.pop('weather')\n",
    "        items.pop('pressure')\n",
    "        items.pop('precipitation')\n",
    "\n",
    "    re = []\n",
    "    for item in items.values():\n",
    "        re.append(item[_start:_end])\n",
    "    re = np.array(re)\n",
    "    re = re.reshape(re.size)\n",
    "    return re\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# path_data = \"data/data.xls\"\n",
    "path_data = \"data/airdata.xlsx\"\n",
    "path_out_txt = \"out/out.txt\"\n",
    "path_out_png = \"out/out.png\"\n",
    "\n",
    "data = xlrd.open_workbook(path_data)\n",
    "table = data.sheet_by_index(0)\n",
    "data_num = table.nrows - 1\n",
    "\n",
    "hour = np.array(table.col_values(1)[1:])\n",
    "pm25 = np.array(table.col_values(2)[1:])\n",
    "o3 = np.array(table.col_values(3)[1:])\n",
    "pm10 = np.array(table.col_values(4)[1:])\n",
    "so2 = np.array(table.col_values(5)[1:])\n",
    "no2 = np.array(table.col_values(6)[1:])\n",
    "co = np.array(table.col_values(7)[1:])\n",
    "temperature = np.array(table.col_values(8)[1:])\n",
    "wind = np.array(table.col_values(9)[1:])\n",
    "weather = np.array(table.col_values(10)[1:])\n",
    "moisture = np.array(table.col_values(11)[1:])\n",
    "pressure = np.array(table.col_values(12)[1:])\n",
    "precipitation = np.array(table.col_values(13)[1:])\n",
    "\n",
    "data.release_resources()\n",
    "del data\n",
    "\n",
    "use_min_max_scaler = True\n",
    "use_all_data = True\n",
    "use_CCA_data = False\n",
    "use_pm25_history = True\n",
    "use_drop_least_importance = False\n",
    "use_deep = False\n",
    "step = 1\n",
    "'''train_deep = 120\n",
    "train_start = 121\n",
    "predict_start = 122'''\n",
    "train_deep = 250\n",
    "train_start = 251\n",
    "predict_start = 252\n",
    "\n",
    "assert step > 0\n",
    "assert train_deep >= step and train_start >= train_deep\n",
    "assert predict_start > train_start\n",
    "'''assert not (use_all_data and use_CCA_data)\n",
    "assert (not use_pm25_history) or (use_all_data and use_pm25_history) or (use_CCA_data and use_pm25_history) or (\n",
    "        use_drop_least_importance and use_pm25_history)\n",
    "assert (not use_drop_least_importance) or ((not use_all_data) and (not use_CCA_data) and use_drop_least_importance)'''\n",
    "\n",
    "regressor_DBN = SupervisedDBNRegression(hidden_layers_structure=[100],\n",
    "                                        learning_rate_rbm=0.01,\n",
    "                                        learning_rate=0.01,\n",
    "                                        n_epochs_rbm=20,\n",
    "                                        n_iter_backprop=200,\n",
    "                                        batch_size=16,\n",
    "                                        activation_function='sigmoid',\n",
    "                                        verbose=False)\n",
    "# regressor_AdaBoost = AdaBoostRegressor()\n",
    "regressor_AdaBoost = AdaBoostRegressor(SupervisedDBNRegression(hidden_layers_structure=[100],\n",
    "                                                               learning_rate_rbm=0.01,\n",
    "                                                               learning_rate=0.01,\n",
    "                                                               n_epochs_rbm=20,\n",
    "                                                               n_iter_backprop=200,\n",
    "                                                               batch_size=16,\n",
    "                                                               activation_function='sigmoid',\n",
    "                                                               verbose=False),\n",
    "                                       loss=\"square\",\n",
    "                                       n_estimators=250,\n",
    "                                       learning_rate=50)\n",
    "regressor_SVM = svm.SVR()\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "open(path_out_txt, 'w').close()\n",
    "\n",
    "Data = dada_handle(\n",
    "    {\"hour\": hour, \"pm25\": pm25, \"o3\": o3, \"pm10\": pm10, \"so2\": so2, \"no2\": no2, \"co\": co, \"temperature\": temperature,\n",
    "     \"wind\": wind, \"weather\": weather, \"moisture\": moisture, \"pressure\": pressure, \"precipitation\": precipitation},\n",
    "    _use_all_data=use_all_data, _use_CCA_data=use_CCA_data, _use_pm25_history=use_pm25_history,\n",
    "    _use_drop_least_importance=use_drop_least_importance, _start=0, _end=step)\n",
    "\n",
    "Target = pm25[step]\n",
    "\n",
    "correct = []\n",
    "predict_DBN = []\n",
    "predict_AdaBoost = []\n",
    "predict_SVM = []\n",
    "loss_total_DBN = 0.0\n",
    "loss_total_AdaBoost = 0.0\n",
    "loss_total_SVM = 0.0\n",
    "\n",
    "logging.debug(\"data_num:%s\", data_num)\n",
    "\n",
    "for i in range(step + 1, data_num):\n",
    "\n",
    "    train_data_last = dada_handle({\"hour\": hour, \"pm25\": pm25, \"o3\": o3, \"pm10\": pm10, \"so2\": so2, \"no2\": no2, \"co\": co,\n",
    "                                   \"temperature\": temperature, \"wind\": wind, \"weather\": weather, \"moisture\": moisture,\n",
    "                                   \"pressure\": pressure, \"precipitation\": precipitation}, _use_all_data=use_all_data,\n",
    "                                  _use_CCA_data=use_CCA_data, _use_pm25_history=use_pm25_history,\n",
    "                                  _use_drop_least_importance=use_drop_least_importance, _start=i - step, _end=i)\n",
    "\n",
    "    logging.debug(\"train_data_last:%s\", train_data_last.shape)\n",
    "    Data = np.row_stack((Data, train_data_last))\n",
    "    Target = np.row_stack((Target, pm25[i]))\n",
    "\n",
    "    # predicting\n",
    "    if i > predict_start:\n",
    "        if use_min_max_scaler:\n",
    "            train_data_last = train_data_last.reshape((1, train_data_last.size))\n",
    "            tmp_test = min_max_scaler.transform(train_data_last)\n",
    "        else:\n",
    "            train_data_last = train_data_last.reshape((1, train_data_last.size))\n",
    "            tmp_test = train_data_last\n",
    "\n",
    "        logging.debug(\"train_data_last:%s\", train_data_last)\n",
    "        logging.debug(\"tmp_test:%s\", tmp_test)\n",
    "        tmp_pred_DBN = regressor_DBN.predict(tmp_test)[0][0]\n",
    "        tmp_pred_AdaBoost = regressor_AdaBoost.predict(tmp_test)[0][0][0][0]\n",
    "        tmp_pred_SVM = regressor_SVM.predict(tmp_test)[0]\n",
    "        logging.info(\"==========================================\")\n",
    "        logging.info(\"pred_DBN:%s\", tmp_pred_DBN)\n",
    "        logging.info(\"pred_AdaBoost:%s\", tmp_pred_AdaBoost)\n",
    "        logging.info(\"pred_SVM:%s\", tmp_pred_SVM)\n",
    "        logging.info(\"correct:%s\", pm25[i])\n",
    "        logging.info(\"==========================================\")\n",
    "\n",
    "        predict_DBN.append(tmp_pred_DBN)\n",
    "        predict_AdaBoost.append(tmp_pred_AdaBoost)\n",
    "        predict_SVM.append(tmp_pred_SVM)\n",
    "        correct.append(pm25[i])\n",
    "\n",
    "        with open(path_out_txt, 'a') as f:\n",
    "            loss_DBN = math.sqrt(math.pow(tmp_pred_DBN - pm25[i], 2)) / pm25[i]\n",
    "            loss_total_DBN += loss_DBN\n",
    "            loss_AdaBoost = math.sqrt(math.pow(tmp_pred_AdaBoost - pm25[i], 2)) / pm25[i]\n",
    "            loss_total_AdaBoost += loss_AdaBoost\n",
    "            loss_SVM = math.sqrt(math.pow(tmp_pred_SVM - pm25[i], 2)) / pm25[i]\n",
    "            loss_total_SVM += loss_SVM\n",
    "            f.write(\n",
    "                \"p_D:%f\\tp_A:%f\\tp_S:%f\\tc:%f\\t\\tl_D:%f\\tl_A:%f\\tl_S:%f\\t\\tR2_D:%f\\tR2_A:%f\\tR2_S:%f\\t\\tl_avg_D:%f\\tl_avg_A:%f\\tl_avg_S:%f\\n\" % (\n",
    "                    tmp_pred_DBN, tmp_pred_AdaBoost, tmp_pred_SVM, pm25[i], loss_DBN, loss_AdaBoost, loss_SVM,\n",
    "                    r2_score(correct, predict_DBN), r2_score(correct, predict_AdaBoost),\n",
    "                    r2_score(correct, predict_SVM), loss_total_DBN / (i - predict_start),\n",
    "                    loss_total_AdaBoost / (i - predict_start),\n",
    "                    loss_total_SVM / (i - predict_start)))\n",
    "\n",
    "        x_range = range(i - predict_start)\n",
    "        plt.clf()\n",
    "        plt.plot(x_range, predict_DBN, marker='o', label=\"DBN\")\n",
    "        plt.plot(x_range, predict_AdaBoost, marker='o', label=\"AdaBoost\")\n",
    "        plt.plot(x_range, predict_SVM, marker='o', label=\"SVM\")\n",
    "        plt.plot(x_range, correct, marker='o', label=\"correct\")\n",
    "        plt.legend(loc='best')\n",
    "        plt.savefig(path_out_png)\n",
    "\n",
    "    # training\n",
    "    if i > train_start:\n",
    "        if use_min_max_scaler:\n",
    "            if use_deep:\n",
    "                tmp_data = min_max_scaler.fit_transform(Data[i - train_deep:i])\n",
    "            else:\n",
    "                tmp_data = min_max_scaler.fit_transform(Data)\n",
    "        else:\n",
    "            if use_deep:\n",
    "                tmp_data = Data[i - train_deep:i]\n",
    "            else:\n",
    "                tmp_data = Data\n",
    "        logging.debug(\"Data:%s\", Data.shape)\n",
    "        logging.debug(\"tmp_data:%s\", tmp_data.shape)\n",
    "        if use_deep:\n",
    "            regressor_DBN.fit(tmp_data, Target[i - train_deep:i, 0])\n",
    "            regressor_AdaBoost.fit(tmp_data, Target[i - train_deep:i, 0])\n",
    "            regressor_SVM.fit(tmp_data, Target[i - train_deep:i, 0])\n",
    "        else:\n",
    "            regressor_DBN.fit(tmp_data, Target[:, 0])\n",
    "            regressor_AdaBoost.fit(tmp_data, Target[:, 0])\n",
    "            regressor_SVM.fit(tmp_data, Target[:, 0])\n",
    "\n",
    "logging.info(\n",
    "    'Done.\\nDBN:\\tR-squared: %f\\nMSE: %f' % (r2_score(correct, predict_DBN), mean_squared_error(correct, predict_DBN)))\n",
    "logging.info('AdaBoost:\\tR-squared: %f\\nMSE: %f' % (\n",
    "    r2_score(correct, predict_AdaBoost), mean_squared_error(correct, predict_AdaBoost)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
